---
title: "Project practical part"
output:
  html_document:
    code_folding: hide
    toc: TRUE
---
  
  
Loading relevant libraries
```{r warning = FALSE, message = FALSE}
knitr::opts_chunk$set(results = "hold")

library(GLMsData)     # Project specific package
library(statmod)      # Project specific package
library(tweedie)      # Project specific package
library(mgcv)         # Project specific package

library(dplyr)        # For data manipulation
library(reshape2)     # For data manipulation
library(tidyverse)    # For data manipulation

library(splines)      # For splines

library(RwR)          # For data set

library(ggplot2)      # For plotting
library(gridExtra)    # For arranging plots
library(grid)         # For arranging plots
library(lattice)      # For plotting splom()

library(Hmisc)        # For multiple imputation
library(mice)         # For multiple imputation
```



```{r warning = FALSE, message = FALSE, echo = FALSE, results = "hide"}
Rain.data = read.table("~/Desktop/Studie/Master/First year/Block 1/Regression/Project/RaindataEromanga.txt", header = TRUE, colClasses = c("integer", "numeric", "integer", "numeric", "factor"))
Rain.data.comp <- complete(mice(Rain.data, method = "pmm", m = 50, seed = 12102024,  printFlag = FALSE))
```


```{r warning = FALSE, message = FALSE}
# Plot rain against year using ggplot
ggplot(data = Rain.data.comp, aes(x = Year, y = Rain)) +
  geom_point() +
  geom_smooth() +
  xlab("Year") +
  ylab("Rain") + 
  ggtitle("Imputed Rain against Year") +
  theme_minimal()

# Plot rain against SOI using ggplot
ggplot(data = Rain.data, aes(x = Year, y = Rain)) +
  geom_point() +
  geom_smooth() +
  xlab("Year") +
  ylab("Rain") +
  ggtitle("Original Rain against Year") +
  theme_minimal()
```


# Analysis using SOI phase

In the following part of the project we seek to fit the Tweedie exponential dispersion model to the data, and predict rainfall as a function of the SOI phase. In order to fit a Tweedie model to the data we need to estimate the nuissance parameter $k$ which we assume to be between 1 and 2. 

## Estimating k with a linear regression model
We initially try to estimate $k$ using the linear relation $VY = \psi \mathcal{V}(\mu) = \psi \mu^k$. This implies that $ \log (VY) = \log(\psi) + k \log(\mu) $. We can therefore estimate $k$ by a linear regression of $\log (VY)$ on $\log(\mu)$. We estimate the variance and mean of the response variable within each SOI phase using the empirical mean and variance:

```{r}
# Compute empirical mean and variance within each SOI phase
Rain.data.grp <- Rain.data.comp %>% group_by(Phase) %>% 
  summarise(meanY = mean(Rain), varY = var(Rain))
```

With estimates of the mean and variance of $Y$ we can proceed to fit an additive linear regression to estimate $k$:

```{r}
# Fit a linear model to the data
lm.fit <- lm(log(varY) ~ log(meanY), data = Rain.data.grp)
summary(lm.fit)
```

We get an initial estimate of $k = 1.406$ and $\psi = \exp(2.054) = 7.800$

```{r}
k_hat <- lm.fit$coef[[2]]
psi_hat <- exp(lm.fit$coef[[1]])
```

Should we consider a different model for instance `glm(varY ~ log(meanY), data = Rain.data.grp, family = Gamma(link = "log"))` or are we happy. The exercise asks us to fit a linear regression model to the data. 


We do a visual sanity check to see how well the model fits the data by plotting the fitted regression line on top of the data:

```{r}
ggplot(data = Rain.data.grp, aes(x = log(meanY), y = log(varY))) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  xlab("log(mean(Y))") +
  ylab("log(var(Y))") +
  ggtitle("log(var(Y)) against log(mean(Y))") +
  theme_minimal()
```
From the plot it appears that the model fits the data reasonably well. We can therefore assume, that the value of $k$ and $\psi$ are reasonable estimates of the true values.


## Fitting a Tweedie model to the data

We can now proceed to fit a Tweedie model to the data. We use the `tweedie` function from the `tweedie` package to fit the model. We use the estimated value of $k$ to fit the model and specifiy `link.power = 0` to use the log-link.


```{r}
# Fit a Tweedie model to the data
tweedie.fit <- glm(Rain ~ Phase, data = Rain.data.comp, family = tweedie(var.power = k_hat, link.power = 0))
summary(tweedie.fit)
```
To interpret the model output we recall the five SOI levels

+ Phase 1: Consistently negative
+ Phase 2: Consistently positive
+ Phase 3: Rapidly falling
+ Phase 4: Rapidly rising
+ Phase 5: Consistently near zero

Note that Phase1 is taken to be the reference phase. The model suggests that the rainfall for Phase 1 is significantly different from 0 with an average rainfall of 

```{r}
predict(tweedie.fit, type = "response", newdata = data.frame(Phase = as.factor(1)))
```
millimeters in July. The model estimates that rainfall for Phase 2 is significantly different from the rainfall in Phase 1 with an average rainfall of 
```{r}
predict(tweedie.fit, type = "response", newdata = data.frame(Phase = as.factor(2)))
```
millimeters in July when SOI is in this phase. The model estimates that the rainfall for Phase 3 is not significantly different from the rainfall in Phase 1 with a predicted rainfall of
```{r}
predict(tweedie.fit, type = "response", newdata = data.frame(Phase = as.factor(3)))
```
millimeters on average in July. The rainfall for Phase 4 is significantly different from the rainfall in Phase 1 according to the model with a predicted average rainfall of 

```{r}
predict(tweedie.fit, type = "response", newdata = data.frame(Phase = as.factor(4)))
```
millimeters in July. The model estimates rainfall for Phase 5 to be borderline significantly different from rainfall in Phase 1 with a predicted average rainfall of 

```{r}
predict(tweedie.fit, type = "response", newdata = data.frame(Phase = as.factor(5)))
```
millimeters in July. Hence, the model suggests that Phase 2 and Phase 4 leads to most rain on average which is when the SOI is consistently positive and rapidly rising respectively. A bit less rain seem to fall on average in Phase 5 which is when the SOI is consistently near zero, while the model predicts least rain on average in SOI phases 1 and 3. That is, according to the model it appears that the rainfall is most intense when the SOI is consistently positive and rapidly rising.

Note that the model predicts $\psi$ to be $8.236$ which is slightly different from the result obtained from the linear regression where $\psi$ was estimated to be $7.800$.



## Estimating probability of zero rain in July
We can use the estimates obtained in the previous exercises to estimate the probability that it will not rain in July. In the theoretical exercises we derived the probability of zero rain to be

$$ \mathbb{P}(Y = 0) = \exp(-\lambda^*) = \exp(-\frac{\mu^{2-k}}{\psi (2-k)}) $$
We have two estimates of $\psi$, one from the linear regression and one from the Tweedie model, so we can try both to estimate the probability that it will not rain in July. If we plug in the estimated values of $k$ and the empirical mean of our data we get the following estimate of the probability that it will not rain:

```{r}
# Estimated probability that it will not rain
psi_hat_tweedie.fit <- summary(tweedie.fit)$dispersion
mu_hat <- mean(Rain.data.comp$Rain)

exp(-mu_hat^(2 - k_hat)/(psi_hat*(2 - k_hat)))
exp(-mu_hat^(2 - k_hat)/(psi_hat_tweedie.fit*(2 - k_hat)))
```
We note that the two results are very similar $33.6$ pct. against $35.6$ pct. We compare this to the empirical probability of zero rain in July:

```{r}
sum(Rain.data.comp$Rain == 0)/nrow(Rain.data.comp)
```
We note that the empirical estimate is $36.7$ pct. which aligns well with both theoretical estimates. We may be tempted to conclude that the dispersion parameter estimated by the Tweedie model is a better estimate of the true dispersion parameter than the one estimated by the linear regression, since the estimated probability of rain from this estimate is closer to the empirical estimate. However, given how close all three predictions are too each other the difference could simply come from the variance in the data, and it is therefore not possible to conclude based on this, that the estimate from the Tweedie model is better than the one from the linear regression.


## Determining k by minimizing AIC
In the following section we consider an alternative estimation procedure of $k$. In particular we will minimize the Akaike Information Criterion (AIC) using a profile likelihood of a model with SOI phase as explanatory variable to determine the optimal value of $k$. We start by constructing a general profile likelihood function that takes a formula, a family, a dataset and an evaluation function as input to calculate some measure we wish to optimize. 

```{r}
profile_likelihood <- function(form, family, data, eval) {
  # Fit GLM model
  model <- glm(form, 
               family = family, 
               data = data)
  
  # Extract eval value using
  eval_val <- eval(model)
  return(eval_val)
}
```

We then define a specific profile likelihood for the Tweedie model as a function of $k$ with `form = Rain ~ Phase`, `family = tweedie(var.power = k, link.power = 0)`, `data = Rain.data.comp` and `eval = AICtweedie`.


```{r}
# Define specific profile likelihood for Tweedie model
tweedie.AIC_profile_likelihood <- function(k) {
  profile_likelihood(form = Rain ~ Phase, 
                         family = tweedie(var.power = k, link.power = 0), 
                         data = Rain.data.comp,
                         eval = AICtweedie)
}
```

We use the `optimize` function to minimize the AIC and find the optimal value of $k$, where we search for $k$ in the range $(1.1, 1.9)$.

```{r}
k_hat_AIC <- optimize(tweedie.AIC_profile_likelihood, lower = 1.1, upper = 1.9)$minimum
k_hat_AIC_obj <- optimize(tweedie.AIC_profile_likelihood, lower = 1.1, upper = 1.9)$objective
k_hat_AIC
```

We note that the optimal value of $k$ using the profile likelihood method is fairly close to the value of $k$ estimated by the linear model

```{r}
k_hat
```

To ensure, that we have in fact found a minimum for $1<k<2$ we plot the AIC against $k$ and add a vertical and a horizontal line at the optimal value of $k$.

```{r}
k_plot_df <- data.frame(k = seq(1.001, 1.999, by = 0.001), AIC = sapply(seq(1.001, 1.999, by = 0.001), FUN = tweedie.AIC_profile_likelihood))

ggplot(data = k_plot_df, aes(x = k, y = AIC)) +
  geom_line() +
  xlab("k") +
  ylab("AIC") +
  ggtitle("AIC against k") +
  theme_minimal() +
  geom_vline(xintercept = k_hat_AIC, linetype = "dashed") +
  geom_hline(yintercept = k_hat_AIC_obj, linetype = "dashed") +
  geom_text(aes(x = k_hat_AIC + 0.01, y = 850, label = paste0("Optimal value of k at ", round(k_hat_AIC,3))), 
            hjust = 0, vjust = 0)
```
We conclude, that the `optimize` function has indeed found the global minimum of the AIC for $1<k<2$. We repeat the analysis from the previous exercises using the optimal value of $k$ found by minimizing the profile likelihood.


## Re-estimating with new value of k

As before we initially fit a Tweedie model to the data using the optimal value of $k$ found by minimizing the AIC.

```{r}
# Fit a Tweedie model to the data
tweedie.fit.AIC <- glm(Rain ~ Phase, data = Rain.data.comp, family = tweedie(var.power = k_hat_AIC, link.power = 0))
summary(tweedie.fit.AIC)
```
We note a slight decrease in the p-value for all the coefficients but the results are very similar to the previous results and the interpretation is the same. This is not surprising since the optimal value of $k$ is very close to the value of $k$ estimated by the linear model. Note however, that the estimated dispersion parameter $\hat \psi_{k_{AIC}} = 7.866$ is slightly different from the previous Tweedie model estimate $\hat \psi_{k_{lin}} = 8.236$ and closer to the linear model estimate $\hat \psi = 7.800$.

We proceed to compute the estimated probability that it will not rain in July. We plug in the estimated values of $k$ and $\psi$ and the empirical mean of our data we get the following estimate of the probability that it will not rain:

```{r}
# Estimated probability that it will not rain
psi_hat_model_AIC <- summary(tweedie.fit.AIC)$dispersion

exp(-mu_hat^(2 - k_hat_AIC)/(psi_hat*(2 - k_hat_AIC)))
exp(-mu_hat^(2 - k_hat_AIC)/(psi_hat_model_AIC*(2 - k_hat_AIC)))
```




## Model diagnostics

We proceed to perform diagnostics of the Tweedie models. We start by constructing a data frame with the relevant diagnostic information for both the Tweedie model based on the linear model estimate of $k$ and the Tweedie model based on the AIC estimate of $k$. We extract the fitted values, Pearson residuals and deviance residuals for both models and add the SOI phase as a variable to the data frame.

```{r}
linmod_diag <- fortify(tweedie.fit)
AIC_diag <- fortify(tweedie.fit.AIC)

diag_df <- data.frame(linmod.fitted = linmod_diag$.fitted,
                      linmod.pearson = residuals(tweedie.fit, type = "pearson"),
                      linmod.deviance = residuals(tweedie.fit, type = "deviance"),
                      AIC.fitted = AIC_diag$.fitted,
                      AIC.pearson = residuals(tweedie.fit.AIC, type = "pearson"),
                      AIC.deviance = residuals(tweedie.fit.AIC, type = "deviance"),
                      SOI = Rain.data.comp$SOI)

summary(diag_df)
```

We then plot the residuals against the fitted values first for the linear model estimate of $k$ and then for the AIC estimate of $k$.


### Linear model estimate of k

```{r, warning=FALSE}
diag_lin_DR_fitted <- qplot(x = linmod.fitted, y = linmod.deviance, data = diag_df) +
  geom_point() +
  geom_smooth() +
  xlab("Fitted values") +
  ylab("Deviance residuals") +
  ggtitle("Deviance residuals against fitted values") +
  theme_bw() +
  theme(plot.title=element_text(size=10))

diag_lin_PR_fitted <- qplot(x = linmod.fitted, y = linmod.pearson, data = diag_df) +
  geom_point() +
  geom_smooth() +
  xlab("Fitted values") +
  ylab("Deviance residuals") +
  ggtitle("Pearson residuals against fitted values") +
  theme_bw() +
  theme(plot.title=element_text(size=10))

diag_lin_DR_SOI <- qplot(x = SOI, y = linmod.deviance, data = diag_df) +
  geom_point() +
  geom_smooth() +
  xlab("SOI") +
  ylab("Deviance residuals") +
  ggtitle("Deviance residuals against SOI") +
  theme_bw() +
  theme(plot.title=element_text(size=10))

diag_lin_PR_SOI <- qplot(x = SOI, y = linmod.pearson, data = diag_df) +
  geom_point() +
  geom_smooth(size = 1) +
  xlab("SOI") +
  ylab("Pearson residuals") +
  ggtitle("Pearson residuals against SOI") +
  theme_bw() +
  theme(plot.title=element_text(size=10))

grid.arrange(diag_lin_DR_fitted, diag_lin_PR_fitted, diag_lin_DR_SOI, diag_lin_PR_SOI, ncol = 2,
             top = textGrob(paste0("k = ", round(k_hat, 3)), gp=gpar(fontsize=20,font=1)))
```
From the plots there is no clear indication that the model is misspecified. The residuals appear to be randomly scattered around zero which indicates that the model captures the mean and variance structure of the data. We further evaluate the plots with bootstrapping. In particular we simulate data from the fitted model. That is, assuming data is from a Tweedie distribution with the estimated mean, dispersion parameter and $k$ we simulate new data and fit a Tweedie model to the new data. We then plot the residuals against the fitted values and the SOI phase for the new data. 


```{r warning=FALSE}
set.seed(10122024)

# Retrieve the estimated mean value of Y given the covariates
linmu_hats <- predict(tweedie.fit, type = "response")

# Use the estimated mean value of Y given the covariates, the estimate of k and the estimated dispersion parameter to simulate new data
yNew1 <- rTweedie(linmu_hats, psi_hat_tweedie.fit, p = k_hat)
yNew2 <- rTweedie(linmu_hats, psi_hat_tweedie.fit, p = k_hat)
yNew3 <- rTweedie(linmu_hats, psi_hat_tweedie.fit, p = k_hat)
yNew4 <- rTweedie(linmu_hats, psi_hat_tweedie.fit, p = k_hat)
yNew5 <- rTweedie(linmu_hats, psi_hat_tweedie.fit, p = k_hat)
yNew6 <- rTweedie(linmu_hats, psi_hat_tweedie.fit, p = k_hat)
simGlmNew1 <- glm(yNew1 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat, link.power = 0))
simGlmNew2 <- glm(yNew2 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat, link.power = 0))
simGlmNew3 <- glm(yNew3 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat, link.power = 0))
simGlmNew4 <- glm(yNew4 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat, link.power = 0))
simGlmNew5 <- glm(yNew5 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat, link.power = 0))
simGlmNew6 <- glm(yNew6 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat, link.power = 0))
simDiagNew1 <- fortify(simGlmNew1)
simDiagNew2 <- fortify(simGlmNew2)
simDiagNew3 <- fortify(simGlmNew3)
simDiagNew4 <- fortify(simGlmNew4)
simDiagNew5 <- fortify(simGlmNew5)
simDiagNew6 <- fortify(simGlmNew6)
p1 <- qplot(.fitted, .resid, data = simDiagNew1) + geom_smooth()
p2 <- qplot(.fitted, .resid, data = simDiagNew2) + geom_smooth()
p3 <- qplot(.fitted, .resid, data = simDiagNew3) + geom_smooth()
p4 <- qplot(.fitted, .resid, data = simDiagNew4) + geom_smooth()
p5 <- qplot(.fitted, .resid, data = simDiagNew5) + geom_smooth()
p6 <- qplot(.fitted, .resid, data = simDiagNew6) + geom_smooth()

grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 3)
```
We see that some of the plots resemble the diagnostic plots of the original model, while others do not. This suggests that the model is not robust to the data generating process which is assumed to be from a Tweedie distribution. We can in particular note, that the simulated Tweedie random variables contain considerably more zeros than the original data:

```{r}
data.frame(Original = sum(Rain.data.comp$Rain == 0), 
           Sim1 = sum(yNew1 == 0),
           Sim2 = sum(yNew2 == 0),
           Sim3 = sum(yNew3 == 0),
           Sim4 = sum(yNew4 == 0),
           Sim5 = sum(yNew5 == 0),
           Sim6 = sum(yNew6 == 0))
```
This suggests that there are some issues with the model and that it does not capture the data very well. We run the same diagnostics on the model with $k$ selected by AIC.

### AIC estimate of k

```{r, warning=FALSE}
diag_AIC_DR_fitted <- qplot(x = AIC.fitted, y = AIC.deviance, data = diag_df) +
  geom_point() +
  geom_smooth() +
  xlab("Fitted values") +
  ylab("Deviance residuals") +
  ggtitle(paste0("Deviance residuals against fitted values for Tweedie model k = ", round(k_hat_AIC, 3))) +
  theme_bw()


diag_AIC_PR_fitted <- qplot(x = AIC.fitted, y = AIC.pearson, data = diag_df) +
  geom_point() +
  geom_smooth() +
  xlab("Fitted values") +
  ylab("Deviance residuals") +
  ggtitle(paste0("Pearson residuals against fitted values for Tweedie model k = ", round(k_hat_AIC, 3))) +
  theme_bw()

diag_AIC_DR_SOI <- qplot(x = SOI, y = AIC.deviance, data = diag_df) +
  geom_point() +
  geom_smooth() +
  xlab("SOI") +
  ylab("Deviance residuals") +
  ggtitle(paste0("Deviance residuals against SOI for Tweedie model k = ", round(k_hat_AIC, 3))) +
  theme_bw()

diag_AIC_PR_SOI <- qplot(x = SOI, y = AIC.deviance, data = diag_df) +
  geom_point() +
  geom_smooth(size = 1) +
  xlab("SOI") +
  ylab("Deviance residuals") +
  ggtitle(paste0("Deviance residuals against SOI for Tweedie model k = ", round(k_hat_AIC, 3))) +
  theme_bw()

grid.arrange(diag_AIC_DR_fitted, diag_AIC_PR_fitted, diag_AIC_DR_SOI, diag_AIC_PR_SOI, ncol = 2)
```

We notice a similar pattern to the previous model.

```{r warning=FALSE}
set.seed(10122024)
AICmu_hats <- predict(tweedie.fit.AIC, type = "response")

AICyNew1 <- rTweedie(AICmu_hats, psi_hat_model_AIC, p = k_hat_AIC)
AICyNew2 <- rTweedie(AICmu_hats, psi_hat_model_AIC, p = k_hat_AIC)
AICyNew3 <- rTweedie(AICmu_hats, psi_hat_model_AIC, p = k_hat_AIC)
AICyNew4 <- rTweedie(AICmu_hats, psi_hat_model_AIC, p = k_hat_AIC)
AICyNew5 <- rTweedie(AICmu_hats, psi_hat_model_AIC, p = k_hat_AIC)
AICyNew6 <- rTweedie(AICmu_hats, psi_hat_model_AIC, p = k_hat_AIC)
AICsimGlmNew1 <- glm(AICyNew1 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat_AIC, link.power = 0))
AICsimGlmNew2 <- glm(AICyNew2 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat_AIC, link.power = 0))
AICsimGlmNew3 <- glm(AICyNew3 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat_AIC, link.power = 0))
AICsimGlmNew4 <- glm(AICyNew4 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat_AIC, link.power = 0))
AICsimGlmNew5 <- glm(AICyNew5 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat_AIC, link.power = 0))
AICsimGlmNew6 <- glm(AICyNew6 ~ Rain.data.comp$Phase, tweedie(var.power = k_hat_AIC, link.power = 0))
AICsimDiagNew1 <- fortify(AICsimGlmNew1)
AICsimDiagNew2 <- fortify(AICsimGlmNew2)
AICsimDiagNew3 <- fortify(AICsimGlmNew3)
AICsimDiagNew4 <- fortify(AICsimGlmNew4)
AICsimDiagNew5 <- fortify(AICsimGlmNew5)
AICsimDiagNew6 <- fortify(AICsimGlmNew6)
AICp1 <- qplot(.fitted, .resid, data = AICsimDiagNew1) + geom_smooth()
AICp2 <- qplot(.fitted, .resid, data = AICsimDiagNew2) + geom_smooth()
AICp3 <- qplot(.fitted, .resid, data = AICsimDiagNew3) + geom_smooth()
AICp4 <- qplot(.fitted, .resid, data = AICsimDiagNew4) + geom_smooth()
AICp5 <- qplot(.fitted, .resid, data = AICsimDiagNew5) + geom_smooth()
AICp6 <- qplot(.fitted, .resid, data = AICsimDiagNew6) + geom_smooth()

grid.arrange(AICp1, AICp2, AICp3, AICp4, AICp5, AICp6, ncol = 3)
```

The pattern appear to be the same as for the previous model. We can also check the number of zeros in the simulated data.

```{r}
data.frame(Original = sum(Rain.data.comp$Rain == 0), 
           Sim1 = sum(AICyNew1 == 0),
           Sim2 = sum(AICyNew2 == 0),
           Sim3 = sum(AICyNew3 == 0),
           Sim4 = sum(AICyNew4 == 0),
           Sim5 = sum(AICyNew5 == 0),
           Sim6 = sum(AICyNew6 == 0))
```

We again notice a similar pattern.

## Conclusion
The model suggests that there is a relation. However we notice that the model may not be the best fit.




## Bootstrap estimates of k

We run into a problem, when we try to bootstrap namely that phase 3 in many bootstrap samples will have only zero values. This mean that the mean and variance in this group becomes zero, so it is not possible to take the log of this group, hence the linear model approach is not possible. In addition we can not use the AIC method as the fitted model used in profile likelihood will not be able to converge. There are a few work arounds. We can either introduce a small value to the zeros, if there are only zeros, but this will likely introduce bias to the results. What we do instead is to artificially inflate the size of the dataset by randomly sampling from the data set. By randomly sampling from the data set we do not introduce any extra information to the model



Since the fitted data produces more zeros and phase 3 in many cases have only zeros, the mean and variance in this group becomes zero, so it is not possible to take the log of this group, hence the linear model approach is not possible. We will therefore use the AIC approach to bootstrap estimate $k$.

```{r}
#set.seed(10122024)
B <- 1000


#sample_index <- sample(120, 500, replace = T)
parametric_k_AIC <- numeric(B)
rain_data_AIC_sample <- Rain.data.comp#[sample_index,]
AICmu_hats_sample <- AICmu_hats#[sample_index]


for (b in 1:B){
  rain_data_AIC_sample$Rain <- rTweedie(AICmu_hats_sample, psi_hat_model_AIC, p = k_hat_AIC)
  
  phase3sum <- rain_data_AIC_sample %>% dplyr::filter(Phase == 3) %>% select(Rain) %>% sum()

  if (phase3sum == 0){
    rain_data_AIC_sample$Rain[rain_data_AIC_sample$Phase == 3] <- rain_data_AIC_sample$Rain[rain_data_AIC_sample$Phase == 3] + abs(rnorm(length(rain_data_AIC_sample$Rain[rain_data_AIC_sample$Phase == 3]), 0.0001, 0.001))
  }

  tweedieBootstrap.AIC_profile_likelihood <- function(k) {
    profile_likelihood(form = Rain ~ Phase, 
                       family = tweedie(var.power = k, link.power = 0), 
                       data = rain_data_AIC_sample,
                       eval = AICtweedie)
  }
  
  k_hat <- optimize(tweedieBootstrap.AIC_profile_likelihood, lower = 1.1, upper = 1.9)$minimum
  
  parametric_k_AIC[b] <- k_hat
}

plot(1:B, parametric_k_AIC)
```


```{r}
#set.seed(10122024)
B <- 1000

#sample_index <- sample(120, 500, replace = T)
parametric_k_LIN <- numeric(B)
rain_data_LIN_sample <- Rain.data.comp#[sample_index,]
LINmu_hats_sample <- linmu_hats#[sample_index]


for (b in 1:B){
  rain_data_LIN_sample$Rain <- rTweedie(LINmu_hats_sample, psi_hat_tweedie.fit, p = k_hat)
  
  phase3sum <- rain_data_LIN_sample %>% dplyr::filter(Phase == 3) %>% select(Rain) %>% sum()

  if (phase3sum == 0){
    rain_data_LIN_sample$Rain[rain_data_LIN_sample$Phase == 3] <- rain_data_LIN_sample$Rain[rain_data_LIN_sample$Phase == 3] + abs(rnorm(length(rain_data_LIN_sample$Rain[rain_data_LIN_sample$Phase == 3]), 0.01, 0.01))
  }

  rain_data_LIN_sample.grp <- rain_data_LIN_sample %>% 
    group_by(Phase) %>% 
    summarise(meanY = mean(Rain), varY = var(Rain))

  LINBootstrapLM <- lm(log(varY) ~ log(meanY), data = rain_data_LIN_sample.grp)
  
  parametric_k_LIN[b] <- coef(LINBootstrapLM)[2]
}

plot(1:B, parametric_k_LIN)
```








