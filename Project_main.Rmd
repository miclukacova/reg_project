---
title: "Regression Aflevering"
author: "Chrsitian Hejstvig Larsen and Michaela Lukacova"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(ggplot2)
theme_set(theme_bw())
library(gridExtra)
library(tidyverse)
library(splines)

# Assignment packages
library(GLMsData)
library(statmod)
library(tweedie)
library(mgcv)

# Imputations
library(mice)
```

# Rainfall and Southern Oscillation Index (SOI) data

```{r data}
Rain.data = read.table("RaindataEromanga.txt", header = TRUE, colClasses = c("integer", "numeric", "integer", "numeric", "factor"))
head(Rain.data)
summary(Rain.data)
```

## Missing data

From the summary we see that only the Rain variable has missing values. The missingness is relatively sparse (7.5 % of the response values). We examine data in order to discover any pattern. 

```{r}
Rain.data[which(is.na(Rain.data$Rain)),] 
```
It seems as if the missingness occurs for consecutive years. Other than that, there is no clear pattern. We have no idea of knowing why data is missing. It could be missing completely at random, at random or not at random. Quite unlikely somebody could have deleted all the large observations of rain fall, this would be missing not at random. Or, more likely, it could simply be that some years the data was not recorded for some reason. This would be missing at random. The fact that the missingness happens for years in a row supports the hypothesis of missing at random rather than completely at random. 

We decide to do multiple imputations in order to account for the missingness. This procedure assumes missing at random. We perform multiple imputations in an attempt not to bias the results of our analysis. 

The multiple imputations are done with help of the aregImpute algorithm.  mice constructs multiple datasets with imputed values for the missing data and then combines the results. There is a certian randomness in each imputation so as not to artificially inflate the information in the data. Using multiple imputations gets rid of the arbitrariness of the imputation. We use the default method, which is predictive mean matching. We use 50 imputations, 50 iterations and a seed of 500.

```{r}
Rain.data <- Rain.data[,c("Rain", "SOI", "Phase", "Year")]
imputed_data <- mice(Rain.data, m = 1, maxit = 50, seed = 10102024, printFlag = FALSE)

complete_data <- complete(imputed_data)
head(complete_data)


# Perform multiple imputation
Rain.data.imputed <- rain.data1
Rain.data.imputed$imputed <- is.na(rain.data1$Rain)

Rain.data.imputation.obj <- aregImpute(~ Year + Rain + SOI + Phase, 
                                       data = Rain.data.imputed, 
                                       n.impute = 5)

imputed_datasets <- list()
for (i in 1:5) {
  imputed_datasets[[i]] <- as.data.frame(impute.transcan(
    Rain.data.imputation.obj, 
    imputation = i, 
    data = Rain.data.imputed, 
    list.out = TRUE, 
    pr = FALSE))
}

mult_impute <- function(form, family){
  glm_fits <- lapply(imputed_datasets, function(imp_data) {
    glm(form, data = imp_data, family = family)
    })
  
  pooled_results <- pool(glm_fits)
  
  return(pooled_results)
}

mult_impute(form = Rain ~ SOI, family = Gamma("log"))


#glm_impute <- function(family, form){
#  fit.mult.impute(form, 
#                  family = family,
#                  data = Rain.data, 
#                  xtrans = Rain.data.imputation.obj$xtrans,
#                  fitter = glm)
#}
#
#glm_impute(family = "gaussian", form = Rain ~ SOI + Phase + Year)
#fit.mult.impute( Rain ~ SOI + Phase + Year,
#                  data = Rain.data, 
#                  xtrans = Rain.data.imputation.obj$xtrans,
#                  fitter = lrm)
```


## EDA

Marginal distributions

```{r}
tmp <- lapply(names(complete_data), function(x)
  ggplot(data = complete_data[, x, drop = FALSE])+
    aes_string(x) + xlab(x) + ylab(""))

gd <- geom_density(adjust = 2, fill = gray(0.5))
gb <- geom_bar(fill = gray(0.5))

grid.arrange(
  tmp[[1]] + gd,
  tmp[[2]] + gd,
  tmp[[3]] + gb,
  tmp[[4]] + gd
)
```
Rain is quite skewed, and there are not many phase 3 observations. 

### SOI and Phase

SOI is a numeric variable, it is the standardized difference between the air pressures at Darwin and Haiti, related to el niño. Phase is a categorical variable, with 5 levels, and is in some way a discretion of the variable SOI. The 5 levels of Phase relate to the sign of SOI but also the direction of this random variable, i.e. whether it is increasing, decreasing or constant. Thus SOI and Phase are related, but both contain information that the other does not. SOI is numeric, and thus more precise, while Phase contains information regarding direction. We investigate how the two variables relate to each other

```{r}
summary(lm(SOI ~ Phase, Rain.data))
```
The adjusted $R^2$ is quite high and the coefficients are highly significant indicating that the Phase variable is a good predictor of SOI. Thus the two variables are very correlated and we must be carefull to include both in our analysis. 

## Analysis using SOI phase

## Analysis using SOI directly

Model the rain fall as a function of SOI. Since the Tweedie model did not fit data very well

### Model rainfall conditionally on having rained

To model the rainfall conditionally on having rained, we first filter out the observations where the rain fall is zero. 

```{r}
rain.data1 <- complete_data %>%
  filter(Rain != 0)
```

We look at the distribution of the rain fall. 

```{r}
ggplot(data = rain.data1, aes(x = Rain)) +
  geom_density(fill = gray(0.5)) +
  xlab("Rain") +
  ylab("Density") +
  ggtitle("Rain fall distribution")
```
The distribution is still very right skewed. This motivates us to consider the Gamma exponential dispersion model, which is typically used to fit positive continous right skewed data. Consider now the rain fall as a function of the SOI. 

```{r warning = FALSE, message = FALSE}
# Plot rain against year using ggplot
ggplot(data = rain.data1, aes(x = SOI, y = Rain)) +
  geom_point() +
  geom_smooth() +
  xlab("SOI") +
  ylab("Rain") + 
  ggtitle("Rain against SOI")

```
There seems to be a positive relationship between the SOI and the rain fall. The plot also indicates a possibility of non linear trends. 

The Gamma exponential dispersion model has the variance structure $\mathcal{V} (\mu) = \mu^2 $. If we choose the log link function we fit the log of the mean of the response variables as a linear combination of the predictors. If we choose the identity link function we fit the mean of the response variables as a linear combination of the predictors. A third option is the canonical link, which is the inverse function. We fit all three models.

```{r}
glm_gamma_log <- glm(Rain ~ SOI, data = rain.data1, family = Gamma("log"))
glm_gamma_id <- glm(Rain ~ SOI, data = rain.data1, family = Gamma("identity"))
glm_gamma_inv <- glm(Rain ~ SOI, data = rain.data1, family = Gamma)
```

Below we calculate the training error based on the squared deviance loss function. 

```{r}
tibble(
  "Link function" = c("Log", "Identity", "Inverse"),
  "Training error" = c(mean(residuals(glm_gamma_log, type = "deviance")^2), 
                       mean(residuals(glm_gamma_id, type = "deviance")^2), 
                       mean(residuals(glm_gamma_inv, type = "deviance")^2))
)
```
The identity link function seems to be the best fit in terms of training error. *Det er lidt mærkeligt, for selvom det virker til at identity linket er det bedste fit, så har vi svært ved at fitte den senere?*. We plot the model fits

```{r}
log_pred <- predict(glm_gamma_log, newdata = rain.data1, type = "response")
id_pred <- predict(glm_gamma_id, newdata = rain.data1, type = "response")
inv_pred <- predict(glm_gamma_inv, newdata = rain.data1, type = "response")

grid.arrange(
  qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = log_pred), color = "red") +
    xlab("SOI") +
    ylab("Rain")+
    ggtitle("Log link function"),
   qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = id_pred), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Identity link function"),
   qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = inv_pred), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Inverse link function"),
  nrow = 1
)
```

*We can see that they all resemble the deviance residuals we had from before. There is something wrong here (??)*

### Should we include additional predictors

```{r}
add1(glm_gamma_log, Rain ~ SOI + Phase + Year, test = "LRT")
```
According to the LRT test there is not evidence in data that suggest that additional predictors should be added to the model. (The LRT test statistic is the comuputed as the difference in deviances between the nested models.)

### Explore possible inclusion of nonlinear effects

We consider to include a non-linear effect of SOI. We consider a natural cubic spline with 2,3,4 degrees of freedom:

```{r}
form1 <- Rain ~ SOI
form2 <- Rain ~ ns(SOI, df = 2)
form3 <- Rain ~ ns(SOI, df = 3)
form4 <- Rain ~ ns(SOI, df = 4)
form5 <- Rain ~ ns(SOI, df = 5)
form6 <- Rain ~ ns(SOI, df = 6)

glm1 <- glm(form1, data = rain.data1, family = Gamma("log"))
glm2 <- glm(form2, data = rain.data1, family = Gamma("log"))
glm3 <- glm(form3, data = rain.data1, family = Gamma("log"))
glm4 <- glm(form4, data = rain.data1, family = Gamma("log"))
glm5 <- glm(form5, data = rain.data1, family = Gamma("log"))
glm6 <- glm(form6, data = rain.data1, family = Gamma("log"))
```

The model fits: 

```{r}
pred1 <- predict(glm1, newdata = rain.data1, type = "response")
pred2 <- predict(glm2, newdata = rain.data1, type = "response")
pred3 <- predict(glm3, newdata = rain.data1, type = "response")
pred4 <- predict(glm4, newdata = rain.data1, type = "response")
pred5 <- predict(glm5, newdata = rain.data1, type = "response")
pred6 <- predict(glm6, newdata = rain.data1, type = "response")

grid.arrange(
  qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = pred1), color = "red") +
    xlab("SOI") +
    ylab("Rain")+
    ggtitle("Df = 1"),
   qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = pred2), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Df = 2"),
   qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = pred3), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Df = 3"),
  qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = pred4), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Df = 4"),   
  qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = pred5), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Df = 5"),
  qplot(rain.data1$SOI, rain.data1$Rain) + 
    geom_line(aes(y = pred6), color = "red") +
    xlab("SOI") +
    ylab("Rain") +
    ggtitle("Df = 6"),
  nrow = 2
)
````

We do cross-validation to compare the four models. We first define the error function. We use

```{r}
# Error function
squared_loss <- function(Y, muhat) mean(Y - muhat)^2
dev_func <- function(Y, muhat) 2 * (Y * (log(Y) - log(muhat)) +
                                    log(log(Y)/log(muhat)))
```

The cross validation function:

```{r}
cv <- function(data, form, B = 1, k = 8, my_family, error_func){
  n <- nrow (data)
  PEcv <- vector("list", B)
  tmp <- numeric(n)
  for (b in 1: B){
    ## Generating the random division into groups
    group <- sample(rep(1:k, length.out = n))
    for (i in 1:k){
      modelcv <- glm(form, data = data[group != i, ], family = my_family)
      muhat <- predict(modelcv, newdata = data[group == i, ], type = "response")
      # !!! change input of error function !!!
      tmp[group == i] <- error_func(data$Rain[group == i],  muhat)
    }
    PEcv[[b]] <- tmp
  }
  mean(unlist(PEcv))
}
```

Cross validation:

```{r}
cv(data = rain.data1, form = form1, B = 1, k = nrow(rain.data1), 
   my_family = Gamma("log"), 
   error_func = squared_loss)

cv(data = rain.data1, form = form2, B = 1, k = nrow(rain.data1), 
   my_family = Gamma("log"), 
   error_func = squared_loss)

cv(data = rain.data1, form = form3, B = 1, k = nrow(rain.data1), 
   my_family = Gamma("log"), 
   error_func = squared_loss)

cv(data = rain.data1, form = form4, B = 1, k = nrow(rain.data1), 
   my_family = Gamma("log"), 
   error_func = squared_loss)

cv(data = rain.data1, form = form5, B = 1, k = nrow(rain.data1), 
   my_family = Gamma("log"), 
   error_func = squared_loss)

cv(data = rain.data1, form = form6, B = 1, k = nrow(rain.data1), 
   my_family = Gamma("log"), 
   error_func = squared_loss)
```
*Jeg har lidt problemer med at bruge deviance loss*. We proceed with the model with 2 degrees of freedom as it has the smallest cross validation error. 

### Model Diagnostics

We do model diagnostics for the chosen model. 

```{r}
mod_final <- glm(form2, data = rain.data1, family = Gamma("log"))

glm_gamma.obj <- transform(
  rain.data1,
  .fitted = predict(mod_final, type = "response"),
  .deviance = residuals(mod_final, type = "deviance"),
  .pearson = residuals(mod_final, type = "pearson")
)

grid.arrange(
  qplot(.fitted, .deviance, data = glm_gamma.obj) + geom_smooth(se = FALSE),
  qplot(.fitted, .pearson, data = glm_gamma.obj) + geom_smooth(se = FALSE),
  qplot(.fitted, sqrt(abs(.pearson)), data = glm_gamma.obj) + geom_smooth(se = FALSE),
  ncol=3
)
```

Looks good. We can see that there is no clear evidence against the model assumptions. We can evaluate these plots via bootstrapping. We compare the residuals with simulated residuals under the null hypothesis that our model is correct.

```{r}
res_plots <- list()
for(i in 1:6){
  print(i)
  sim_data <- simulate(mod_final)[,1]
  simGlm <- glm(sim_data ~ rain.data1$SOI, family = Gamma(link = "log"))
  res_plots[[i]] <- qplot(fitted(simGlm), residuals(simGlm, type = "deviance")) + 
    xlab("Fitted values") +
    ylab("Deviance residuals") +
    geom_smooth()
}

grid.arrange(res_plots[[1]], res_plots[[2]], res_plots[[3]], res_plots[[4]],
              res_plots[[5]], res_plots[[6]], ncol = 3)

```
*Der er noget som går galt her...*. 

### Report a final model

Final model fit

```{r}
qplot(rain.data1$SOI, rain.data1$Rain) + 
  geom_line(aes(y = pred2), color = "red") +
  xlab("SOI") +
  ylab("Rain") +
  ggtitle("Rain ~ ns(SOI, df = 2)")
```

### Interpretation of the results.

```{r}
summary(mod_final)
```


## Model with Tweedie

jeg ved ikke lige helt hvad man gør her... vi kender jeg ikke k hvis det er for soi? og der er vel ikke en nem måde at estimere det på?

```{r}
tweedie.fit <- glm(Rain ~ SOI, 
                   data = complete_data, 
                   family = tweedie(var.power = k_hat, link.power = 0))
```



