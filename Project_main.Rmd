---
title: "Regression Aflevering"
author: "Chrsitian Hejstvig Larsen and Michaela Lukacova"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(ggplot2)
theme_set(theme_bw())
library(gridExtra)
library(tidyverse)
library(splines)

# Assignment packages
library(GLMsData)
library(statmod)
library(tweedie)
library(mgcv)

# Imputations
library(mice)
```

# Rainfall and Southern Oscillation Index (SOI) data

```{r data}
Rain.data = read.table("RaindataEromanga.txt", header = TRUE, colClasses = c("integer", "numeric", "integer", "numeric", "factor"))
head(Rain.data)
summary(Rain.data)
```

## Missing data

From the summary we see that only the Rain variable has missing values. The missingness is relatively sparse (7.5 % of the response values). We examine data in order to discover any pattern. 

```{r}
Rain.data[which(is.na(Rain.data$Rain)),] 
```
It seems as if the missingness occurs for consecutive years. Other than that, there is no clear pattern. We have no idea of knowing why data is missing. It could be missing completely at random, at random or not at random. Quite unlikely somebody could have deleted all the large observations of rain fall, this would be missing not at random. Or, more likely, it could simply be that some years the data was not recorded for some reason. This would be missing at random. The fact that the missingness happens for years in a row supports the hypothesis of missing at random rather than completely at random. 

We decide to do multiple imputations in order to account for the missingness. This procedure assumes missing at random. We perform multiple imputations in an attempt not to bias the results of our analysis. 

The multiple imputations are done with help of the aregImpute algorithm.  mice constructs multiple datasets with imputed values for the missing data and then combines the results. There is a certian randomness in each imputation so as not to artificially inflate the information in the data. Using multiple imputations gets rid of the arbitrariness of the imputation. We use the default method, which is predictive mean matching. We use 50 imputations, 50 iterations and a seed of 500.

```{r}
Rain.data <- Rain.data[,c("Rain", "SOI", "Phase", "Year")]
imputed_data <- mice(Rain.data, m = 1, maxit = 50, seed = 10102024, printFlag = FALSE)

complete_data <- complete(imputed_data)
head(complete_data)


# Perform multiple imputation
#Rain.data.imputed <- Rain.data
#Rain.data.imputed$imputed <- is.na(Rain.data.imputed$Rain)
#
#Rain.data.imputation.obj <- aregImpute(~ Year + Rain + SOI + Phase, 
#                                       data = Rain.data.imputed, 
#                                       n.impute = 5)
#
#
#glm_impute <- function(family, form){
#  fit.mult.impute(form, 
#                  family = family,
#                  data = Rain.data, 
#                  xtrans = Rain.data.imputation.obj$xtrans,
#                  fitter = glm)
#}
#
#glm_impute(family = "gaussian", form = Rain ~ SOI + Phase + Year)
#fit.mult.impute( Rain ~ SOI + Phase + Year,
#                  data = Rain.data, 
#                  xtrans = Rain.data.imputation.obj$xtrans,
#                  fitter = lrm)
```


## EDA

Marginal distributions

```{r}
tmp <- lapply(names(complete_data), function(x)
  ggplot(data = complete_data[, x, drop = FALSE])+
    aes_string(x) + xlab(x) + ylab(""))

gd <- geom_density(adjust = 2, fill = gray(0.5))
gb <- geom_bar(fill = gray(0.5))

grid.arrange(
  tmp[[1]] + gd,
  tmp[[2]] + gd,
  tmp[[3]] + gb,
  tmp[[4]] + gd
)
```
Rain is quite skewed, and there are not many phase 3 observations. 

### SOI and Phase

SOI is a numeric variable, it is the standardized difference between the air pressures at Darwin and Haiti, related to el niÃ±o. Phase is a categorical variable, with 5 levels, and is in some way a discretion of the variable SOI. The 5 levels of Phase relate to the sign of SOI but also the direction of this random variable, i.e. whether it is increasing, decreasing or constant. Thus SOI and Phase are related, but both contain information that the other does not. SOI is numeric, and thus more precise, while Phase contains information regarding direction. We investigate how the two variables relate to each other

```{r}
summary(lm(SOI ~ Phase, Rain.data))
```
The adjusted $R^2$ is quite high and the coefficients are highly significant indicating that the Phase variable is a good predictor of SOI. Thus the two variables are very correlated and we must be carefull to include both in our analysis. 

## Analysis using SOI phase

## Analysis using SOI directly

Model the rain fall as a function of SOI.

### Model rainfall conditionally on having rained

To model the rainfall conditionally on having rained, we first filter out the observations where the rain fall is zero. 

```{r}
rain.data1 <- complete_data %>%
  filter(Rain != 0)
```

We look at the distribution of the rain fall. 

```{r}
ggplot(data = rain.data1, aes(x = Rain)) +
  geom_density(fill = gray(0.5)) +
  xlab("Rain") +
  ylab("Density") +
  ggtitle("Rain fall distribution")
```
The distribution is still very right skewed. This motivates us to consider the Gamma exponential dispersion model, which is typically used to fit positive continous right skewed data. Consider now the rain fall as a function of the SOI. 

```{r warning = FALSE, message = FALSE}
# Plot rain against year using ggplot
ggplot(data = rain.data1, aes(x = SOI, y = Rain)) +
  geom_point() +
  geom_smooth() +
  xlab("SOI") +
  ylab("Rain") + 
  ggtitle("Rain against SOI")

```
There seems to be a positive relationship between the SOI and the rain fall. The plot also indicates a possibility of non linear trends. 

Performing the estimation of $k$ as in we the analysis using SOI Phase we obtain a $k$ parameter very close to $2$. 

```{r}
# Compute empirical mean and variance within each SOI phase
Rain.data.grp <- rain.data1 %>% group_by(Phase) %>% 
  summarise(meanY = mean(Rain), varY = var(Rain))

# Fit a linear model to the data
lm.fit <- lm(log(varY) ~ log(meanY), data = Rain.data.grp)
summary(lm.fit)

# Estimates
k_hat <- lm.fit$coef[[2]]
psi_hat <- exp(lm.fit$coef[[1]])
k_hat; psi_hat

ggplot(data = Rain.data.grp, aes(x = log(meanY), y = log(varY))) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  xlab("log(mean(Y))") +
  ylab("log(var(Y))") +
  ggtitle("log(var(Y)) against log(mean(Y))") +
  theme_bw()
```

The linear model seems to be a good fit, and the k parameter is significant. The Gamma model would therefore be a reasonable candidate as the exponential dispersion models. The Gamma exponential dispersion model has the variance structure $\mathcal{V} (\mu) = \mu^2 $. If we choose the log link function we fit the log of the mean  of the response variables as a linear combination of the predictors. If we choose the identity link function we fit the mean of the response variables as a linear combination of the predictors. We fit both models.

```{r}
glm_gamma_log <- glm(Rain ~ SOI, data = rain.data1, family = Gamma("log"))
glm_gamma_id <- glm(Rain ~ SOI, data = rain.data1, family = Gamma("identity"))

summary(glm_gamma_log)
summary(glm_gamma_id)

grid.arrange(
qplot(SOI, Rain, data = rain.data1) +
  geom_smooth(method = "glm", method.args = list(family = Gamma("log")), se = FALSE), 
qplot(SOI, Rain, data = rain.data1) +
  geom_smooth(method = "glm", method.args = list(family = Gamma("identity")), se = FALSE),
nrow = 1
)
```

At a first glance the model fit looks fine. The variable SOI is highly significant. 

Training error
```{r}

```


We do model diagnostics

```{r}
glm_gamma.obj1 <- transform(
  rain.data1,
  .fitted = predict(glm_gamma_log, type = "response"),
  .deviance = residuals(glm_gamma_log, type = "deviance"),
  .pearson = residuals(glm_gamma_log, type = "pearson")
)

grid.arrange(
  qplot(.fitted, .deviance, data = glm_gamma.obj1) + geom_smooth(se = FALSE),
  qplot(.fitted, .pearson, data = glm_gamma.obj1) + geom_smooth(se = FALSE),
  #qplot(.fitted, sqrt(abs(.pearson)), data = glm_gamma.obj1) + geom_smooth(se = FALSE),
  ncol=2
)

glm_gamma.obj2 <- transform(
  rain.data1,
  .fitted = predict(glm_gamma_id, type = "response"),
  .deviance = residuals(glm_gamma_id, type = "deviance"),
  .pearson = residuals(glm_gamma_id, type = "pearson")
)

grid.arrange(
  qplot(.fitted, .deviance, data = glm_gamma.obj2) + geom_smooth(se = FALSE),
  qplot(.fitted, .pearson, data = glm_gamma.obj2) + geom_smooth(se = FALSE),
  #qplot(.fitted, sqrt(abs(.pearson)), data = glm_gamma.obj2) + geom_smooth(se = FALSE),
  ncol=2
)
```
The residual plots from the gamma model with log link function seem better than with the canonical link? We can see that there is no clear evidence against the model assumptions. We can evaluate these plots via bootstrapping. We compare the residuals with simulated residuals under the null hypothesis that our model is correct.

```{r}
res_plots <- list()
for(i in 1:4){
  sim_data <- simulate(glm_gamma_log)[,1]
  simGlm <- glm(sim_data ~ rain.data1$SOI, family = Gamma(link = "log"))
  mods[[i]] <- simGlm
  res_plots[[i]] <- qplot(fitted(simGlm), residuals(simGlm, type = "deviance")) + 
    xlab("Fitted values") +
    ylab("Deviance residuals") +
    geom_smooth()
}

grid.arrange(res_plots[[1]], res_plots[[2]], res_plots[[3]], res_plots[[4]], ncol = 2)

```
We can see that they all resemble the deviance residuals we had from before.
We can also compare the estimated variance function with the empirical mean-variance relationship.

We do cross-validation to compare the two models. We first define the error function:

```{r}
# Error function
dev_func <- function(Y, m, muhat) 2 * (Y * log(Y / (m * muhat)) + 
                                          (m - Y) * log((m - Y) / (m * (1 - muhat))))
```
*$Y$ is the number of dead beetles, $m$ is the total number of beetles, and $\muhat$ is the model's probability of dying.*

The cross validation function:

```{r}
cv <- function(data, form, B = 1, k = 8, my_family, error_func){
  n <- nrow (data)
  PEcv <- vector("list", B)
  tmp <- numeric(n)
  for (b in 1: B){
    ## Generating the random division into groups
    group <- sample(rep(1:k, length.out = n))
    for (i in 1:k){
      modelcv <- glm(form, data = data[group != i, ], family = my_family)
      muhat <- predict(modelcv, newdata = data[group == i, ], type = "response")
      # !!! change input of error function !!!
      tmp[group == i] <- error_func(data$Dead[group == i], data$Total[group == i], muhat)
    }
    PEcv[[b]] <- tmp
  }
  mean(unlist(PEcv))
}
```

Specifying the form:

```{r}
form <- matrix(c(Dead, Total - Dead), 7, 2) ~ Dose
```

Cross validation:

```{r}
cv(data = beetle.data, form = form, B = 1, k = 8, my_family = binomial(link=logit), error_func = dev_func)
```

For the second model:

```{r}
form2 <- matrix(c(Dead, Total - Dead), 7, 2) ~ Dose + Method
cv(data = beetle.data, form = form2, B = 1, k = 8, my_family = binomial(link=logit), error_func = dev_func)
```

We should not include more predictors: 

```{r}
add1(glm_gamma_log, Rain ~ SOI + Phase + Year, test = "LRT")
```
According to the LRT test there is not evidence in data 



## Model with Tweedie

```{r}
tweedie.fit <- glm(Rain ~ Phase, data = Rain.data.comp, family = tweedie(var.power = k_hat, link.power = 0))
```



